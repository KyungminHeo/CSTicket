"""
LangGraph Orchestrator ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
Kafkaì—ì„œ í‹°ì¼“ ì´ë²¤íŠ¸ë¥¼ ì†Œë¹„í•˜ê³  LangGraph ì›Œí¬í”Œë¡œìš°ë¡œ ì²˜ë¦¬

ì‹¤í–‰ ë°©ë²•:
    cd orchestrator
    python -m app.main

ì²˜ë¦¬ íë¦„:
1. Kafka "ticket-events" í† í”½ êµ¬ë…
2. ìƒˆ í‹°ì¼“ ì´ë²¤íŠ¸ ìˆ˜ì‹ 
3. LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (classify â†’ generate â†’ validate)
4. Redisì— ì‹¤ì‹œê°„ ìƒíƒœ ì—…ë°ì´íŠ¸
5. Kafka "agent-results" í† í”½ì— ê²°ê³¼ ë°œí–‰
"""
import asyncio
import signal
import sys
from pathlib import Path
from datetime import datetime

# shared íŒ¨í‚¤ì§€ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from shared import (
    get_settings,
    get_redis_client,
    KafkaConsumerClient,
    KafkaProducerClient,
    TOPIC_TICKET_EVENTS,
    TOPIC_AGENT_RESULTS,
    TicketStatus,
    TicketCategory,
    TicketPriority,
    AgentResultEvent,
)
from app.graph import TicketState, create_initial_state, app as workflow_app


class Orchestrator:
    """
    ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í´ë˜ìŠ¤
    
    ì—­í• :
    - Kafka Consumerë¡œ í‹°ì¼“ ì´ë²¤íŠ¸ ìˆ˜ì‹ 
    - LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    - Redisë¡œ ì‹¤ì‹œê°„ ìƒíƒœ ì—…ë°ì´íŠ¸
    - Kafka Producerë¡œ ê²°ê³¼ ë°œí–‰
    """
    
    def __init__(self):
        self.settings = get_settings()
        
        # Kafka Consumer ì„¤ì •
        # - í† í”½: ticket-events (ìƒˆ í‹°ì¼“ ì´ë²¤íŠ¸)
        # - ê·¸ë£¹: orchestrator-group (ê°™ì€ ê·¸ë£¹ ë‚´ ì¸ìŠ¤í„´ìŠ¤ê°€ íŒŒí‹°ì…˜ ë¶„ë°°)
        self.consumer = KafkaConsumerClient(
            topics=[TOPIC_TICKET_EVENTS],
            group_id="orchestrator-group"
        )
        
        # Kafka Producer (ì²˜ë¦¬ ê²°ê³¼ ë°œí–‰ìš©)
        self.producer = KafkaProducerClient()
        
        self.redis = None
        self._running = False
    
    async def start(self):
        """
        Orchestrator ì‹œì‘
        
        1. Redis ì—°ê²°
        2. Kafka Consumer ì‹œì‘
        3. Kafka Producer ì‹œì‘
        4. ì´ë²¤íŠ¸ ì†Œë¹„ ë£¨í”„ ì‹œì‘
        """
        print("ğŸš€ Starting LangGraph Orchestrator...")
        
        # Redis ì—°ê²° (ìƒíƒœ ì €ì¥ìš©)
        self.redis = await get_redis_client()
        print("âœ… Redis connected")
        
        # Kafka Consumer ì‹œì‘ (ì´ë²¤íŠ¸ ìˆ˜ì‹ ìš©)
        await self.consumer.start()
        print("âœ… Kafka consumer started")
        
        # Kafka Producer ì‹œì‘ (ê²°ê³¼ ë°œí–‰ìš©)
        await self.producer.start()
        print("âœ… Kafka producer started")
        
        self._running = True
        print("ğŸ¯ Listening for ticket events...")
        
        # ë¬´í•œ ë£¨í”„ë¡œ ì´ë²¤íŠ¸ ì†Œë¹„ ì‹œì‘
        # ìƒˆ ì´ë²¤íŠ¸ê°€ ë“¤ì–´ì˜¬ ë•Œë§ˆë‹¤ _handle_ticket_event í˜¸ì¶œ
        await self.consumer.consume(self._handle_ticket_event)
    
    async def stop(self):
        """
        Orchestrator ì¢…ë£Œ
        
        ëª¨ë“  ì—°ê²° ì •ë¦¬ (Graceful Shutdown)
        """
        print("\nğŸ›‘ Stopping orchestrator...")
        self._running = False
        
        await self.consumer.stop()
        await self.producer.stop()
        if self.redis:
            await self.redis.disconnect()
        
        print("âœ… Orchestrator stopped")
    
    async def _handle_ticket_event(self, event: dict):
        """
        Kafka í‹°ì¼“ ì´ë²¤íŠ¸ ì²˜ë¦¬
        
        Gatewayê°€ ë°œí–‰í•œ TicketCreatedEventë¥¼ ì²˜ë¦¬
        
        Args:
            event: Kafka ë©”ì‹œì§€ í˜ì´ë¡œë“œ
                {
                    "ticket_id": "t-abc123",
                    "user_id": "user-uuid",
                    "content": "ê²°ì œê°€ ì•ˆ ë©ë‹ˆë‹¤",
                    "metadata": {...},
                    "created_at": "2026-02-06T..."
                }
        """
        ticket_id = event.get("ticket_id")
        user_id = event.get("user_id")
        content = event.get("content")
        metadata = event.get("metadata", {})
        
        print(f"\nğŸ“¥ Processing ticket: {ticket_id}")
        
        try:
            # 1. ì´ˆê¸° ìƒíƒœ ìƒì„±
            initial_state = create_initial_state(
                ticket_id=ticket_id,
                user_id=user_id,
                content=content,
                metadata=metadata
            )
            
            # 2. Redis ìƒíƒœ ì—…ë°ì´íŠ¸ (í´ë§ìš©)
            await self.redis.set_ticket_status(ticket_id, "classifying", progress=10)
            
            # 3. LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            final_state = await self._run_workflow(initial_state)
            
            # 4. ê²°ê³¼ë¥¼ Kafkaì— ë°œí–‰
            await self._publish_result(final_state)
            
            print(f"âœ… Ticket {ticket_id} processed: {final_state.status}")
            
        except Exception as e:
            print(f"âŒ Error processing ticket {ticket_id}: {e}")
            # ì‹¤íŒ¨ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
            await self.redis.set_ticket_status(ticket_id, "failed", progress=0)
    
    async def _run_workflow(self, initial_state: TicketState) -> TicketState:
        """
        LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        
        ì›Œí¬í”Œë¡œìš° ë…¸ë“œ:
        1. classify: í‹°ì¼“ ë¶„ë¥˜ (ì¹´í…Œê³ ë¦¬, ìš°ì„ ìˆœìœ„, íƒœê·¸)
        2. generate: RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        3. validate: í’ˆì§ˆ ê²€ì¦
           - í†µê³¼ â†’ complete
           - ì¬ì‹œë„ í•„ìš” â†’ generateë¡œ ëŒì•„ê°
           - 3íšŒ ì‹¤íŒ¨ â†’ escalate
        
        Args:
            initial_state: ì´ˆê¸° í‹°ì¼“ ìƒíƒœ
            
        Returns:
            ìµœì¢… ì²˜ë¦¬ ìƒíƒœ (completed, escalated, failed ì¤‘ í•˜ë‚˜)
        """
        ticket_id = initial_state.ticket_id
        state_dict = initial_state.model_dump()
        
        # ê° ë‹¨ê³„ë³„ ì§„í–‰ë¥  ë§¤í•‘
        progress_map = {
            "classifying": 25,   # ë¶„ë¥˜ ì¤‘
            "generating": 50,    # ì‘ë‹µ ìƒì„± ì¤‘
            "validating": 75,    # í’ˆì§ˆ ê²€ì¦ ì¤‘
            "completed": 100,    # ì²˜ë¦¬ ì™„ë£Œ
            "escalated": 100,    # ì—ìŠ¤ì»¬ë ˆì´ì…˜
            "failed": 0,         # ì‹¤íŒ¨
        }
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
        # astream: ê° ë…¸ë“œ ì‹¤í–‰ í›„ ì¤‘ê°„ ìƒíƒœ yield
        async for event in workflow_app.astream(state_dict):
            # event: {ë…¸ë“œì´ë¦„: ë…¸ë“œì‹¤í–‰í›„ìƒíƒœ}
            for node_name, node_state in event.items():
                status = node_state.get("status", "pending")
                progress = progress_map.get(status, 0)
                
                # Redis ìƒíƒœ ì—…ë°ì´íŠ¸ (í´ë¼ì´ì–¸íŠ¸ í´ë§ìš©)
                await self.redis.set_ticket_status(ticket_id, status, progress)
                
                # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ì¥ì•  ë³µêµ¬ìš©)
                await self.redis.save_agent_state(ticket_id, node_state)
                
                # ìµœì¢… ìƒíƒœ ìœ ì§€
                state_dict = node_state
        
        # ì²˜ë¦¬ ì™„ë£Œ í›„ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ
        await self.redis.delete_agent_state(ticket_id)
        
        return TicketState(**state_dict)
    
    async def _publish_result(self, state: TicketState):
        """
        ì²˜ë¦¬ ê²°ê³¼ë¥¼ Kafkaì— ë°œí–‰
        
        Topic: agent-results
        Gatewayê°€ ì´ ì´ë²¤íŠ¸ë¥¼ ì†Œë¹„í•˜ì—¬ DB ì—…ë°ì´íŠ¸ (TODO)
        
        Args:
            state: ìµœì¢… í‹°ì¼“ ìƒíƒœ
        """
        event = AgentResultEvent(
            ticket_id=state.ticket_id,
            category=TicketCategory(state.category) if state.category else TicketCategory.OTHER,
            priority=TicketPriority(state.priority) if state.priority else TicketPriority.MEDIUM,
            response=state.final_response or state.draft_response or "",
            quality_score=state.quality_score,
            status=TicketStatus(state.status),
            completed_at=datetime.utcnow()
        )
        
        await self.producer.send_agent_result(event)


# ============================================================
# ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
# ============================================================

async def main():
    """
    Orchestrator ì‹¤í–‰ ë©”ì¸ í•¨ìˆ˜
    
    Ctrl+C (SIGINT) ë˜ëŠ” SIGTERM ì‹œ graceful shutdown
    """
    orchestrator = Orchestrator()
    
    # ì¢…ë£Œ ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
    loop = asyncio.get_event_loop()
    
    def signal_handler():
        asyncio.create_task(orchestrator.stop())
    
    for sig in (signal.SIGINT, signal.SIGTERM):
        try:
            loop.add_signal_handler(sig, signal_handler)
        except NotImplementedError:
            # WindowsëŠ” add_signal_handler ë¯¸ì§€ì›
            pass
    
    try:
        await orchestrator.start()
    except KeyboardInterrupt:
        await orchestrator.stop()


if __name__ == "__main__":
    asyncio.run(main())
